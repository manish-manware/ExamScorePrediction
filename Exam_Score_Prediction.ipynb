{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5525e474",
   "metadata": {},
   "source": [
    "# Exam Score Prediction using Linear Regression\n",
    "\n",
    "## Project Overview\n",
    "This project predicts exam scores using various student features including age, study hours, class attendance, sleep quality, and other factors. We'll implement linear regression from scratch using NumPy.\n",
    "\n",
    "## Dataset\n",
    "- **File**: Exam_Score_Prediction.csv\n",
    "- **Samples**: 234 student records\n",
    "- **Target**: exam_score\n",
    "- **Features**: 12 input features including demographic, behavioral, and environmental factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(50)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1151f0",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../Exam_Score_Prediction.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst Few Rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical Columns: {categorical_cols}\")\n",
    "print(f\"Numerical Columns: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c67ca8",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing and Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0581589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Separate features and target\n",
    "X = df_processed.drop('exam_score', axis=1)\n",
    "y = df_processed['exam_score'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Identify columns to encode\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        print(f\"{col}: {X[col].nunique()} unique values - {X[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cdb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Encoded {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "print(\"\\nFeatures after encoding:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7345d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = X.values.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures normalized (mean â‰ˆ 0, std â‰ˆ 1)\")\n",
    "print(f\"Training features mean: {X_train.mean(axis=0)[:5].round(3)}\")\n",
    "print(f\"Training features std: {X_train.std(axis=0)[:5].round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c8561e",
   "metadata": {},
   "source": [
    "## Step 3: Implement Linear Regression from Scratch using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionNumPy:\n",
    "    \"\"\"\n",
    "    Linear Regression implementation using NumPy.\n",
    "    Uses the Normal Equation method: Î² = (X^T X)^-1 X^T y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coefficients = None\n",
    "        self.intercept = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the linear regression model using the Normal Equation.\n",
    "        \n",
    "        Parameters:\n",
    "        X: Training features (n_samples, n_features)\n",
    "        y: Training target values (n_samples,)\n",
    "        \"\"\"\n",
    "        # Add bias term (column of ones) to X\n",
    "        X_with_bias = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        \n",
    "        # Normal Equation: Î² = (X^T X)^-1 X^T y\n",
    "        # Calculate X^T X\n",
    "        XTX = X_with_bias.T @ X_with_bias\n",
    "        \n",
    "        # Calculate X^T y\n",
    "        XTy = X_with_bias.T @ y\n",
    "        \n",
    "        # Solve for coefficients: Î² = (X^T X)^-1 X^T y\n",
    "        coefficients = np.linalg.solve(XTX, XTy)\n",
    "        \n",
    "        # Store intercept and coefficients\n",
    "        self.intercept = coefficients[0]\n",
    "        self.coefficients = coefficients[1:]\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        print(f\"Model trained successfully!\")\n",
    "        print(f\"Intercept: {self.intercept:.4f}\")\n",
    "        print(f\"Number of features: {len(self.coefficients)}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on new data.\n",
    "        \n",
    "        Parameters:\n",
    "        X: Features (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        Predicted values\n",
    "        \"\"\"\n",
    "        if self.coefficients is None:\n",
    "            raise ValueError(\"Model has not been fitted yet!\")\n",
    "        \n",
    "        # Linear regression equation: y = b0 + b1*x1 + b2*x2 + ... + bn*xn\n",
    "        predictions = self.intercept + X @ self.coefficients\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Calculate RÂ² score on given data.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        ss_res = np.sum((y - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        return r2\n",
    "\n",
    "print(\"LinearRegressionNumPy class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0897ad",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "model = LinearRegressionNumPy()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Coefficients (Feature Weights):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = [col for col in df.drop('exam_score', axis=1).columns]\n",
    "\n",
    "# Display coefficients sorted by absolute value\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': model.coefficients\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d2a4f",
   "metadata": {},
   "source": [
    "## Step 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on train and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    \"\"\"Calculate and display evaluation metrics.\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"  Mean Squared Error (MSE):     {mse:.4f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"  Mean Absolute Error (MAE):    {mae:.4f}\")\n",
    "    print(f\"  RÂ² Score:                     {r2:.4f}\")\n",
    "    \n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Model Performance Metrics\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training Set\")\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Testing Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c68b6",
   "metadata": {},
   "source": [
    "## Step 6: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Actual vs Predicted (Training Set)\n",
    "axes[0, 0].scatter(y_train, y_train_pred, alpha=0.6, color='blue', label='Predictions')\n",
    "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('Actual Exam Score')\n",
    "axes[0, 0].set_ylabel('Predicted Exam Score')\n",
    "axes[0, 0].set_title(f'Training Set: Actual vs Predicted (RÂ² = {train_metrics[\"R2\"]:.4f})')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Actual vs Predicted (Testing Set)\n",
    "axes[0, 1].scatter(y_test, y_test_pred, alpha=0.6, color='green', label='Predictions')\n",
    "axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 1].set_xlabel('Actual Exam Score')\n",
    "axes[0, 1].set_ylabel('Predicted Exam Score')\n",
    "axes[0, 1].set_title(f'Testing Set: Actual vs Predicted (RÂ² = {test_metrics[\"R2\"]:.4f})')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals Plot (Training Set)\n",
    "train_residuals = y_train - y_train_pred\n",
    "axes[1, 0].scatter(y_train_pred, train_residuals, alpha=0.6, color='blue')\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 0].set_xlabel('Predicted Exam Score')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('Training Set: Residual Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals Plot (Testing Set)\n",
    "test_residuals = y_test - y_test_pred\n",
    "axes[1, 1].scatter(y_test_pred, test_residuals, alpha=0.6, color='green')\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 1].set_xlabel('Predicted Exam Score')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Testing Set: Residual Plot')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_evaluation.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved as 'model_evaluation.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171963f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Get top features by absolute coefficient value\n",
    "top_n = 10\n",
    "coef_sorted = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': model.coefficients\n",
    "}).reindex(pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': model.coefficients\n",
    "}).sort_values('Coefficient', key=abs, ascending=False).index)\n",
    "\n",
    "coef_top = coef_sorted.head(top_n)\n",
    "\n",
    "colors = ['green' if x > 0 else 'red' for x in coef_top['Coefficient']]\n",
    "ax.barh(coef_top['Feature'], coef_top['Coefficient'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Coefficient Value')\n",
    "ax.set_title('Top 10 Feature Importance in Linear Regression Model')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature importance visualization saved as 'feature_importance.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of residuals\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Training residuals histogram\n",
    "axes[0].hist(train_residuals, bins=20, color='blue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Residuals')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(f'Training Residuals Distribution\\n(Mean: {train_residuals.mean():.4f}, Std: {train_residuals.std():.4f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Testing residuals histogram\n",
    "axes[1].hist(test_residuals, bins=20, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Residuals')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title(f'Testing Residuals Distribution\\n(Mean: {test_residuals.mean():.4f}, Std: {test_residuals.std():.4f})')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('residuals_distribution.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Residuals distribution saved as 'residuals_distribution.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d88e7e",
   "metadata": {},
   "source": [
    "## Step 7: Model Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdffa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAM SCORE PREDICTION MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET INFORMATION:\")\n",
    "print(f\"   â€¢ Total Samples: {len(df)}\")\n",
    "print(f\"   â€¢ Training Samples: {len(X_train)}\")\n",
    "print(f\"   â€¢ Testing Samples: {len(X_test)}\")\n",
    "print(f\"   â€¢ Number of Features: {X_train.shape[1]}\")\n",
    "print(f\"   â€¢ Target Variable: exam_score\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ MODEL ARCHITECTURE:\")\n",
    "print(f\"   â€¢ Algorithm: Linear Regression (Normal Equation)\")\n",
    "print(f\"   â€¢ Implementation: NumPy\")\n",
    "print(f\"   â€¢ Equation: y = {model.intercept:.4f} + Î£(Î²_i Ã— x_i)\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ TRAINING PERFORMANCE:\")\n",
    "print(f\"   â€¢ RÂ² Score: {train_metrics['R2']:.4f}\")\n",
    "print(f\"   â€¢ RMSE: {train_metrics['RMSE']:.4f}\")\n",
    "print(f\"   â€¢ MAE: {train_metrics['MAE']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ§ª TESTING PERFORMANCE:\")\n",
    "print(f\"   â€¢ RÂ² Score: {test_metrics['R2']:.4f}\")\n",
    "print(f\"   â€¢ RMSE: {test_metrics['RMSE']:.4f}\")\n",
    "print(f\"   â€¢ MAE: {test_metrics['MAE']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ” TOP 5 MOST IMPORTANT FEATURES (by coefficient magnitude):\")\n",
    "top_features = coef_df.head(5)\n",
    "for idx, row in top_features.iterrows():\n",
    "    print(f\"   {idx+1}. {row['Feature']:20s}: {row['Coefficient']:8.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "print(f\"   â€¢ Model explains {test_metrics['R2']*100:.2f}% variance in exam scores\")\n",
    "print(f\"   â€¢ Average prediction error: Â±{test_metrics['MAE']:.2f} points\")\n",
    "print(f\"   â€¢ Model is {'GOOD' if test_metrics['R2'] > 0.7 else 'MODERATE' if test_metrics['R2'] > 0.5 else 'POOR'}\")\n",
    "print(f\"   â€¢ No significant overfitting detected\" if abs(train_metrics['R2'] - test_metrics['R2']) < 0.1 else \"   â€¢ Some overfitting detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da420f",
   "metadata": {},
   "source": [
    "## Step 8: Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample predictions\n",
    "print(\"\\nðŸ“‹ Sample Predictions from Test Set:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_indices = np.random.choice(len(y_test), 10, replace=False)\n",
    "sample_df = pd.DataFrame({\n",
    "    'Actual Score': y_test[sample_indices].round(2),\n",
    "    'Predicted Score': y_test_pred[sample_indices].round(2),\n",
    "    'Error': (y_test[sample_indices] - y_test_pred[sample_indices]).round(2),\n",
    "    'Error %': ((abs(y_test[sample_indices] - y_test_pred[sample_indices]) / y_test[sample_indices]) * 100).round(2)\n",
    "})\n",
    "\n",
    "print(sample_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNote: Error % shows the percentage difference between actual and predicted scores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
